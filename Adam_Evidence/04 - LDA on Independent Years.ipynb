{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75695ac3",
   "metadata": {},
   "source": [
    "# LDA on Independent Years\n",
    "\n",
    "As we were unable to get the LDA sequence model to work efficiently, we decided to see what the effect would be if we looked at the years independently and then compare this to the LDA across the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43881ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf28599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Status</th>\n",
       "      <th>Description</th>\n",
       "      <th>References</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-1999-0001</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['ipinputc', 'bsdderived', 'tcpip', 'implement...</td>\n",
       "      <td>BUGTRAQ:19981223 Re: CERT Advisory CA-98.13 - ...</td>\n",
       "      <td>Modified (20051217)</td>\n",
       "      <td>MODIFY(1) Frech  |     NOOP(2) Northcutt, W...</td>\n",
       "      <td>Christey&gt; A Bugtraq posting indicates that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-1999-0002</td>\n",
       "      <td>Entry</td>\n",
       "      <td>['buffer', 'overflow', 'nfs', 'mountd', 'give'...</td>\n",
       "      <td>BID:121   |   URL:http://www.securityfocus.com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-1999-0003</td>\n",
       "      <td>Entry</td>\n",
       "      <td>['execute', 'command', 'root', 'buffer', 'over...</td>\n",
       "      <td>BID:122   |   URL:http://www.securityfocus.com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVE-1999-0004</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['mime', 'buffer', 'overflow', 'email', 'clien...</td>\n",
       "      <td>CERT:CA-98.10.mime_buffer_overflows   |   MS:M...</td>\n",
       "      <td>Modified (19990621)</td>\n",
       "      <td>ACCEPT(8) Baker, Cole, Collins, Dik, Landfi...</td>\n",
       "      <td>Frech&gt; Extremely minor, but I believe e-mail i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVE-1999-0005</td>\n",
       "      <td>Entry</td>\n",
       "      <td>['arbitrary', 'command', 'execution', 'imap', ...</td>\n",
       "      <td>BID:130   |   URL:http://www.securityfocus.com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166896</th>\n",
       "      <td>CVE-2021-46482</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['jsish', 'v', 'discover', 'contain', 'heap', ...</td>\n",
       "      <td>MISC:https://github.com/pcmacdon/jsish/issues/66</td>\n",
       "      <td>Assigned (20220124)</td>\n",
       "      <td>None (candidate not yet proposed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166897</th>\n",
       "      <td>CVE-2021-46483</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['jsish', 'v', 'discover', 'contain', 'heap', ...</td>\n",
       "      <td>MISC:https://github.com/pcmacdon/jsish/issues/62</td>\n",
       "      <td>Assigned (20220124)</td>\n",
       "      <td>None (candidate not yet proposed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166898</th>\n",
       "      <td>CVE-2021-46559</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['firmware', 'moxa', 'tn', 'device', 'weak', '...</td>\n",
       "      <td>MISC:https://www.moxa.com/en/support/product-s...</td>\n",
       "      <td>Assigned (20220126)</td>\n",
       "      <td>None (candidate not yet proposed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166899</th>\n",
       "      <td>CVE-2021-46560</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['firmware', 'moxa', 'tn', 'device', 'allow', ...</td>\n",
       "      <td>MISC:https://www.moxa.com/en/support/product-s...</td>\n",
       "      <td>Assigned (20220126)</td>\n",
       "      <td>None (candidate not yet proposed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166900</th>\n",
       "      <td>CVE-2021-46561</td>\n",
       "      <td>Candidate</td>\n",
       "      <td>['controllerorgcontrollerorgcontrollerjs', 'cv...</td>\n",
       "      <td>CONFIRM:https://github.com/CVEProject/cve-serv...</td>\n",
       "      <td>Assigned (20220126)</td>\n",
       "      <td>None (candidate not yet proposed)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166901 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name     Status  \\\n",
       "0        CVE-1999-0001  Candidate   \n",
       "1        CVE-1999-0002      Entry   \n",
       "2        CVE-1999-0003      Entry   \n",
       "3        CVE-1999-0004  Candidate   \n",
       "4        CVE-1999-0005      Entry   \n",
       "...                ...        ...   \n",
       "166896  CVE-2021-46482  Candidate   \n",
       "166897  CVE-2021-46483  Candidate   \n",
       "166898  CVE-2021-46559  Candidate   \n",
       "166899  CVE-2021-46560  Candidate   \n",
       "166900  CVE-2021-46561  Candidate   \n",
       "\n",
       "                                              Description  \\\n",
       "0       ['ipinputc', 'bsdderived', 'tcpip', 'implement...   \n",
       "1       ['buffer', 'overflow', 'nfs', 'mountd', 'give'...   \n",
       "2       ['execute', 'command', 'root', 'buffer', 'over...   \n",
       "3       ['mime', 'buffer', 'overflow', 'email', 'clien...   \n",
       "4       ['arbitrary', 'command', 'execution', 'imap', ...   \n",
       "...                                                   ...   \n",
       "166896  ['jsish', 'v', 'discover', 'contain', 'heap', ...   \n",
       "166897  ['jsish', 'v', 'discover', 'contain', 'heap', ...   \n",
       "166898  ['firmware', 'moxa', 'tn', 'device', 'weak', '...   \n",
       "166899  ['firmware', 'moxa', 'tn', 'device', 'allow', ...   \n",
       "166900  ['controllerorgcontrollerorgcontrollerjs', 'cv...   \n",
       "\n",
       "                                               References  \\\n",
       "0       BUGTRAQ:19981223 Re: CERT Advisory CA-98.13 - ...   \n",
       "1       BID:121   |   URL:http://www.securityfocus.com...   \n",
       "2       BID:122   |   URL:http://www.securityfocus.com...   \n",
       "3       CERT:CA-98.10.mime_buffer_overflows   |   MS:M...   \n",
       "4       BID:130   |   URL:http://www.securityfocus.com...   \n",
       "...                                                   ...   \n",
       "166896   MISC:https://github.com/pcmacdon/jsish/issues/66   \n",
       "166897   MISC:https://github.com/pcmacdon/jsish/issues/62   \n",
       "166898  MISC:https://www.moxa.com/en/support/product-s...   \n",
       "166899  MISC:https://www.moxa.com/en/support/product-s...   \n",
       "166900  CONFIRM:https://github.com/CVEProject/cve-serv...   \n",
       "\n",
       "                      Phase  \\\n",
       "0       Modified (20051217)   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3       Modified (19990621)   \n",
       "4                       NaN   \n",
       "...                     ...   \n",
       "166896  Assigned (20220124)   \n",
       "166897  Assigned (20220124)   \n",
       "166898  Assigned (20220126)   \n",
       "166899  Assigned (20220126)   \n",
       "166900  Assigned (20220126)   \n",
       "\n",
       "                                                    Votes  \\\n",
       "0          MODIFY(1) Frech  |     NOOP(2) Northcutt, W...   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3          ACCEPT(8) Baker, Cole, Collins, Dik, Landfi...   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "166896                  None (candidate not yet proposed)   \n",
       "166897                  None (candidate not yet proposed)   \n",
       "166898                  None (candidate not yet proposed)   \n",
       "166899                  None (candidate not yet proposed)   \n",
       "166900                  None (candidate not yet proposed)   \n",
       "\n",
       "                                                 Comments  \n",
       "0       Christey> A Bugtraq posting indicates that the...  \n",
       "1                                                     NaN  \n",
       "2                                                     NaN  \n",
       "3       Frech> Extremely minor, but I believe e-mail i...  \n",
       "4                                                     NaN  \n",
       "...                                                   ...  \n",
       "166896                                                NaN  \n",
       "166897                                                NaN  \n",
       "166898                                                NaN  \n",
       "166899                                                NaN  \n",
       "166900                                                NaN  \n",
       "\n",
       "[166901 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/formatted_df.csv\").drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850af1b9",
   "metadata": {},
   "source": [
    "We found that the way that we saved the data frame, meant that the Description column was read as a string rather than a list as it was intended. Therefore, we had to apply the function literal_eval which allows us to convert the string of a stored list into a python list. We then separate the description column into a list to allow easier access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349be42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Description'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c97422",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0933fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1541, 2778, 4313, 6663, 8161, 10794, 15380, 22238, 28578, 35549, 40436, 45428, 50015, 55416, 61536, 69815, 77731, 86931, 101250, 116731, 132000, 149784, 166901]\n"
     ]
    }
   ],
   "source": [
    "names = df['Name']\n",
    "year = []\n",
    "for instance in names:\n",
    "    year.append(int(instance[4:8]))\n",
    "year_count = [0]\n",
    "for i in range(23):\n",
    "    if i == 0:\n",
    "        year_count.append(year.count(i+1999))\n",
    "    else:\n",
    "        year_count.append(year.count(i+1999) + year_count[i]) \n",
    "print(year_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596b2cc",
   "metadata": {},
   "source": [
    "Here we create a dictionary of words that occur in the whole data set, allowing us to index each of these words. We also format the documents of each year into a matrix which indicates how many times each word occurs in each document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36bd80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = gensim.corpora.Dictionary(desc)\n",
    "doc_word_matrix_array = []\n",
    "for i in range(23):\n",
    "    doc_word_matrix_array.append([vocab.doc2bow(doc) for doc in desc[year_count[i]:year_count[i+1]]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f86fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b797f",
   "metadata": {},
   "source": [
    "### Model Training using CV\n",
    "\n",
    "After trying to find an optimal number of topics, we decided to use 50 as this is what was used in Analyzing Evolving Trends of Vulnerabilities in National Vulnerability Database by Williams et al., which is what provided us the idea for this project. We did a 6-Fold cross validation on each year as this helps to ensure that we don't overfit and so helps provide a better overview of how the topics change over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5779e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/.local/lib/python3.8/site-packages/gensim/models/ldamodel.py:849: RuntimeWarning: overflow encountered in exp2\n",
      "  perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=6, random_state=27, shuffle=True)\n",
    "ldamodels=[]\n",
    "for i in range(23):\n",
    "    models = []\n",
    "    coherence = []\n",
    "    j=0\n",
    "    for split in kf.split(desc[year_count[i]:year_count[i+1]]): \n",
    "        train = [vocab.doc2bow(doc) for doc in desc[split[0]]]\n",
    "        test = [vocab.doc2bow(doc) for doc in desc[split[1]]]\n",
    "        models.append(LDA(corpus=train, id2word=vocab, passes = 3, num_topics = 50))  \n",
    "        coherence.append(CoherenceModel(model=models[j], corpus=test, dictionary=vocab, coherence='u_mass').get_coherence())\n",
    "        j += j\n",
    "    ldamodels.append(models[coherence.index(min(coherence))]) #append the model, corresponding to the best coherence, to the list of final yearly models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504d0e3",
   "metadata": {},
   "source": [
    "The below was created for Bill to use on his model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS TO BE USED FOR THE CV FOR LDA ON THE WHOLE DATA SET\n",
    "\n",
    "vocab = gensim.corpora.Dictionary(desc)\n",
    "doc_word_matrix_array = []\n",
    "for i in range(23):\n",
    "    doc_word_matrix_array.append([vocab.doc2bow(doc) for doc in desc[year_count[i]:year_count[i+1]]]) \n",
    "\n",
    "\n",
    "kf = KFold(n_splits=6, random_state=27, shuffle=True)\n",
    "train=[[] * 6] \n",
    "test=[[] * 6]\n",
    "for i in range(23): # For each year work out the CV split and combine all of the years into one big test and train dataset\n",
    "    j=0\n",
    "    for split in kf.split(desc[year_count[i]:year_count[i+1]]):\n",
    "        train[j].extend([vocab.doc2bow(doc) for doc in desc[split[0]]])\n",
    "        test[j].extend([vocab.doc2bow(doc) for doc in desc[split[1]]])\n",
    "        j += j      \n",
    "for j in range(6):\n",
    "    temp_model = LDA(corpus=train[j], id2word=vocab, passes = 3, num_topics = 50) #Traing model here \n",
    "    temp_coherence = CoherenceModel(model=model, corpus=test[j], dictionary=vocab, coherence='u_mass').get_coherence()\n",
    "    if temp_coherence > coherence:\n",
    "        model = temp_model\n",
    "        coherence = temp_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3b4da",
   "metadata": {},
   "source": [
    "### Topic matching between years\n",
    "\n",
    "Tried this implementation but did not work, accoriding to an issue reported on the Github, this is because there are too many nodes, so I will use a different implementation of the Hungarian algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a38720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hungarian-algorithm\n",
    "from hungarian-algorithm import algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ecac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to extract the top 50 words in each topic and return a list of topics containing the list of 50 words\n",
    "def extract_Words(model): \n",
    "    topics=[]\n",
    "    topic_index=[]\n",
    "    for words in model.show_topics(num_topics = 50, num_words = 50, formatted=False):\n",
    "        (a,b) = words #removes the index\n",
    "        word=[]\n",
    "        for j in b:\n",
    "            (c,d) = j #extracts the word from the (word, probability) tuple\n",
    "            word.append(c)\n",
    "        topics.append(word)\n",
    "        topic_index.append(int(a))\n",
    "    return (topics,topic_index)\n",
    "\n",
    "#Creates a dictionary of jaccard scores\n",
    "#Requires topics1 and topics2 to have 50 topics in each\n",
    "def graphify(topics1, topics2):\n",
    "    G = {}\n",
    "    for i in range(50):\n",
    "        jaccard_dict = {}\n",
    "        for j in range(50):\n",
    "            jaccard_dict[j+50] = jaccard_score(topics1[i],topics2[j],average='macro')\n",
    "        G[i] = jaccard_dict\n",
    "        print(jaccard_dict)\n",
    "    return G\n",
    "\n",
    "#find best match between topic-sets and change topic-set 2 numbering to replicate topic-set 1.\n",
    "def match_sets(G,index1):\n",
    "    matching = algorithm.find_matching(G, matching_type = 'max', return_type = 'list')\n",
    "    new_index2=[]*50\n",
    "    for i in range(50):\n",
    "        (a,b) = matching[i]\n",
    "        (c,d) = a\n",
    "        new_index2[d-50]=index1[c] \n",
    "    return new_index2\n",
    "\n",
    "topicWords=[]\n",
    "indices=[]\n",
    "for i in range(23):\n",
    "    (topics, indexes) = extract_Words(ldamodels[i])\n",
    "    topicWords.append(topics)\n",
    "    indices.append(indexes)\n",
    "topic_map = [Indices[0]]\n",
    "for i in range(22):\n",
    "    G = graphify(topicWords[i],topicWords[i+1])\n",
    "    next_topic_index = match_sets(G,indices[i])\n",
    "    topic_map.append(next_topic_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6ed52",
   "metadata": {},
   "source": [
    "We now need to correlate the topics from each year to eachother. This is important for our analysis as the topic labelled 27 in year 1999 could be related to DDoS vulnerabilities, while this could be labelled as 9 in year 2000. Therefore, we need to correlate all the topics so we can see how the proportions of the same topic changes. To do this we are going to use a Jaccard similarity to work out how similar a topic from year i compares to each of the topics in year i+1. We then create a matrix of this and solve the matching problem that maximises the similarity of the topics between years. To do this we use the linear_sum_assignment function to solve this efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to extract the top 500 words in each topic and return a list of topics containing the list of 500 words\n",
    "def extract_Words(model): \n",
    "    topics=[]\n",
    "    topic_index=[]\n",
    "    for words in model.show_topics(num_topics = 50, num_words = 500, formatted=False):\n",
    "        (a,b) = words #removes the index\n",
    "        word=[]\n",
    "        for j in b:\n",
    "            (c,d) = j #extracts the word from the (word, probability) tuple\n",
    "            word.append(c)\n",
    "        topics.append(word)\n",
    "        topic_index.append(int(a))\n",
    "    return (topics,topic_index)\n",
    "\n",
    "#Creates a matrix of the Jaccard scores\n",
    "#Requires topics1 and topics2 to have 50 topics in each\n",
    "def calculate_cost(topics1, topics2):\n",
    "    cost = []\n",
    "    for i in range(50):\n",
    "        jaccard = []\n",
    "        for j in range(50):\n",
    "            jaccard.append(jaccard_score(topics1[i],topics2[j],average='macro'))\n",
    "        cost.append(jaccard) \n",
    "    return cost\n",
    "\n",
    "#find best match between topic-sets and change topic-set 2 numbering to replicate topic-set 1.\n",
    "def match_sets(cost,index1):\n",
    "    row_ind, col_ind = linear_sum_assignment(cost)\n",
    "    new_index2=[0]*50\n",
    "    for i in range(50):\n",
    "        new_index2[col_ind[i]]=index1[row_ind[i]] \n",
    "    return new_index2\n",
    "\n",
    "topicWords=[]\n",
    "indices=[]\n",
    "for i in range(23):\n",
    "    (topics, indexes) = extract_Words(ldamodels[i])\n",
    "    topicWords.append(topics)\n",
    "    indices.append(indexes)\n",
    "topic_map = [Indices[0]]\n",
    "for i in range(22):\n",
    "    cost = calculate_cost(topicWords[i],topicWords[i+1])\n",
    "    if i == 0:\n",
    "        print(cost[0])\n",
    "    next_topic_index = match_sets(cost,indices[i])\n",
    "    topic_map.append(next_topic_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e89cc0",
   "metadata": {},
   "source": [
    "Originally, we looked at the top 50 words from each topic, however we found that the jaccard scores were very low and many were 0. Therefore, we decided to increase the number of words to 500 as we thought that this would provide enough words to compare, while allowing us to compute in a reasonable time. As you can see from the output (which is the Jaccard scores for topic\\[0\\] in year 1999 compared to each of the topics in year 2000), this did not have as much of an effect as we had hoped. It is clear from the output that there is very little correlation between topics generated from the LDA model in each year. It is possible that it is showing that there is a very great change between the different vulnerabilties reported in each year, however we believe it is much more likely that it is a poor model that we have created. Therefore, we have decided that this approach does not provide a useful result that we can use to analyse the change of vulnerability types over time. \n",
    "\n",
    "It would have been nice to have come up with a similarity measure that took into consideration the probabilities of each word occuring in a topic, however we did not have time to implement this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
